{"id":70279,"no":17,"title":"Page 17","content":"United States Robots and Mechanical Men Corporation had a problem. The problem was people.\n Peter Bogert, Senior Mathematician, was on his way to Assembly when he encountered Alfred Lanning, Research Director. Lanning was bending his ferocious white eyebrows together and staring down across the railing into the computer room.\n On the floor below the balcony, a trickle of humanity of both sexes and various ages was looking about curiously, while a guide intoned a set speech about robotic computing.\n \"This computer you see before you,\" he said, \"is the largest of its type in the world. It contains five million three hundred thousand cryotrons and is capable of dealing simultaneously with over one hundred thousand variables. With its help, U. S. Robots is able to design with precision the positronic brains of new models. \"The requirements are fed in on tape which is perforated by the action of this keyboard-something like a very complicated typewriter or linotype machine, except that it does not deal with letters but with concepts. Statements are broken down into the symbolic logic equivalents and those in turn converted to perforation patterns.\n \"The computer can, in less than one hour, present our scientists with a design for a brain which will give all the necessary positronic paths to make a robot...\"\n Alfred Lanning looked up at last and noticed the other. \"Ah, Peter,\" he said.\n Bogert raised both hands to smooth down his already perfectly smooth and glossy head of black hair. He said, \"You don\u0027t look as though you think much of this, Alfred.\"\n Lanning grunted. The idea of public guided tours of U. S. Robots was of fairly recent origin, and was supposed to serve a dual function. On the one hand, the theory went, it allowed people to see robots at close quarters and counter their almost instinctive fear of the mechanical objects through increased familiarity. And on the other hand, it was supposed to interest at least an occasional person in taking up robotics research as a life work.\n \"You know I don\u0027t,\" Lanning said finally. \"Once a week, work is disrupted. Considering the man-hours lost, the return is insufficient.\"\n \"Still no rise in job applications, then?\"\n \"Oh, some, but only in the categories where the need isn\u0027t vital. It\u0027s research men that are needed. You know that. The trouble is that with robots forbidden on Earth itself, there\u0027s something unpopular about being a roboticist.\"\n \"The damned Frankenstein complex,\" said Bogert, consciously imitating one of the other\u0027s pet phrases.\n Lanning missed the gentle jab. He said, \"I ought to be used to it, but I never will. You\u0027d think that by now every human being on Earth would know that the Three Laws represented a perfect safeguard; that robots are simply not dangerous. Take this bunch.\" He glowered down. \"Look at them. Most of them go through the robot assembly room for the thrill of fear, like riding a roller coaster. Then when they enter the room with the MEC model-damn it, Peter, a MEC model that will do nothing on God\u0027s green Earth but take two steps forward, say \u0027Pleased to meet you, sir,\u0027 shake hands, then take two steps back-they back away and mothers snatch up their kids. How do we expect to get brainwork out of such idiots?\"\n Bogert had no answer. Together, they stared down once again at the line of sightseers, now passing out of the computer room and into the positronic brain assembly section. Then they left. They did not, as it turned out, observe Mortimer W. Jacobson, age 16-who, to do him complete justice, meant no harm whatever.\n In fact, it could not even be said to be Mortimer\u0027s fault. The day of the week on which the tour took place was known to all workers.\n All devices in its path ought to have been carefully neutralized or locked, since it was unreasonable to expect human beings to withstand the temptation to handle knobs, keys, handles and pushbuttons. In addition, the guide ought to have been very carefully on the watch for those who succumbed.\n But, at the time, the guide had passed into the next room and Mortimer was tailing the line. He passed the keyboard on which instructions were fed into the computer. He had no way of suspecting that the plans for a new robot design were being fed into it at that moment, or, being a good kid, he would have avoided the keyboard. He had no way of knowing that, by what amounted to almost criminal negligence, a technician had not inactivated the keyboard.\n So Mortimer touched the keys at random as though he were playing a musical instrument.\n He did not notice that a section of perforated tape stretched itself out of the instrument in another part of the room-soundlessly, unobtrusively.\n Nor did the technician, when he returned, discover any signs of tampering. He felt a little uneasy at noticing that the keyboard was live, but did not think to check. After a few minutes, even his first trifling uneasiness was gone, and he continued feeding data into the computer.\n As for Mortimer, neither then, nor ever afterward, did he know what he had done.\n The new LNE model was designed for the mining of boron in the asteroid belt. The boron hydrides were increasing in value yearly as primers for the proton micropiles that carried the ultimate load of power production on spaceships, and Earth\u0027s own meager supply was running thin.\n Physically, that meant that the LNE robots would have to be equipped with eyes sensitive to those lines prominent in the spectroscopic analysis of boron ores and the type of limbs most useful for the working up of ore to finished product. As always, though, the mental equipment was the major problem.\n The first LNE positronic brain had been completed now. It was the prototype and would join all other prototypes in U. S. Robots\u0027 collection. When finally tested, others would then be manufactured for leasing (never selling) to mining corporations.\n LNE-Prototype was complete now. Tall, straight, polished, it looked from outside like any of a number of not-too-specialized robot models.\n The technician in charge, guided by the directions for testing in the Handbook of Robotics, said, \"How are you?\"\n The indicated answer was to have been, \"I am well and ready to begin my functions. I trust you are well, too,\" or some trivial modification thereof.\n This first exchange served no purpose but to show that the robot could hear, understand a routine question, and make a routine reply congruent with what one would expect of a robotic attitude. Beginning from there, one could pass on to more complicated matters that would test the different Laws and their interaction with the specialized knowledge of each particular model.\n So the technician said, \"How are you?\" He was instantly jolted by the nature of LNE-Prototype\u0027s voice. It had a quality like no robotic voice he had ever heard (and he had heard many). It formed syllables like the chimes of a low-pitched celeste.\n So surprising was this that it was only after several moments that the technician heard, in retrospect, the syllables that had been formed by those heavenly tones. They were, \"Da, da, da, goo.\" The robot still stood tall and straight but its right hand crept upward and a finger went into its mouth.\n The technician stared in absolute horror and bolted. He locked the door behind him and, from another room, put in an emergency call to Dr. Susan Calvin.\n Dr. Susan Calvin was U. S. Robots\u0027 (and, virtually, mankind\u0027s) only robopsychologist. She did not have to go very far in her testing of LNE-Prototype before she called very peremptorily for a transcript of the computer-drawn plans of the positronic brain-paths and the taped instructions that had directed them. After some study, she, in turn, sent for Bogert.\n Her iron-gray hair was drawn severely back; her cold face, with its strong vertical lines marked off by the horizontal gash of the pale, thin-lipped mouth, turned intensely upon him.\n \"What is this, Peter?\" Bogert studied the passages she pointed out with increasing stupefaction and said, \"Good Lord, Susan, it makes no sense.\"\n \"It most certainly doesn\u0027t. How did it get into the instructions?\" The technician in charge, called upon, swore in all sincerity that it was none of his doing, and that he could not account for it. The computer checked out negative for all attempts at flaw-finding.\n \"The positronic brain,\" said Susan Calvin, thoughtfully, \"is past redemption. So many of the higher functions have been cancelled out by these meaningless directions that the result is very like a human baby.\"\n Bogert looked surprised, and Susan Calvin took on a frozen attitude at once, as she always did at the least expressed or implied doubt of her word. She said, \"We make every effort to make a robot as mentally like a man as possible. Eliminate what we call the adult functions and what is naturally left is a human infant, mentally speaking. Why do you look so surprised, Peter?\"\n LNE-Prototype, who showed no signs of understanding any of the things that were going on around it, suddenly slipped into a sitting position and began a minute examination of its feet.\n Bogert stared at it. \"It\u0027s a shame to have to dismantle the creature. It\u0027s a handsome job.\"\n \"Dismantle it?\" said the robopsychologist forcefully. \"Of course, Susan. What\u0027s the use of this thing? Good Lord, if there\u0027s one object completely and abysmally useless it\u0027s a robot without a job it can perform. You don\u0027t pretend there\u0027s a job this thing can do, do you?\"\n \"No, of course not.\"\n \"Well, then?\"\n Susan Calvin said, stubbornly, \"I want to conduct more tests.\" Bogert looked at her with a moment\u0027s impatience, then shrugged. If there was one person at U. S. Robots with whom it was useless to dispute, surely that was Susan Calvin. Robots were all she loved, and long association with them, it seemed to Bogert, had deprived her of any appearance of humanity. She was no more to be argued out of a decision than was a triggered micropile to be argued out of operating.\n \"What\u0027s the use?\" he breathed; then aloud, hastily: \"Will you let us know when your tests are complete?\"\n \"I will,\" she said. \"Come, Lenny.\"\n (LNE, thought Bogert. That becomes Lenny. Inevitable.)\n Susan Calvin held out her hand but the robot only stared at it. Gently, the robopsychologist reached for the robot\u0027s hand and took it. Lenny rose smoothly to its feet (its mechanical coordination, at least, worked well). Together they walked out, robot topping woman by two feet. Many eyes followed them curiously down the long corridors.\n One wall of Susan Calvin\u0027s laboratory, the one opening directly off her private office, was covered with a highly magnified reproduction of a positronic-path chart. Susan Calvin had studied it with absorption for the better part of a month.\n She was considering it now, carefully, tracing the blunted paths through their contortions. Behind her, Lenny sat on the floor, moving its legs apart and together, crooning meaningless syllables to itself in a voice so beautiful that one could listen to the nonsense and be ravished.\n Susan Calvin turned to the robot, \"Lenny-Lenny-\"\n She repeated this patiently until finally Lenny looked up and made an inquiring sound. The robopsychologist allowed a glimmer of pleasure to cross her face fleetingly. The robot\u0027s attention was being gained in progressively shorter intervals.\n She said, \"Raise your hand, Lenny. Hand-up. Hand-up.\" She raised her own hand as she said it, over and over.\n Lenny followed the movement with its eyes. Up, down, up, down. Then it made an abortive gesture with its own hand and chimed, \"Eh-uh.\"\n \"Very good, Lenny,\" said Susan Calvin, gravely. \"Try it again. Hand-up.\"\n Very gently, she reached out her own hand, took the robot\u0027s, and raised it, lowered it. \"Hand-up. Hand-up.\"\n A voice from her office called and interrupted. \"Susan?\"\n Calvin halted with a tightening of her lips. \"What is it, Alfred?\" The research director walked in, and looked at the chart on the wall and at the robot. \"Still at it?\"\n \"I\u0027m at my work, yes.\"\n \"Well, you know, Susan...\" He took out a cigar, staring at it hard, and made as though to bite off the end. In doing so, his eyes met the woman\u0027s stern look of disapproval; and he put the cigar away and began over. \"Well, you know, Susan, the LNE model is in production now.\"\n \"So I\u0027ve heard. Is there something in connection with it you wish of me?\"\n \"No-o. Still, the mere fact that it is in production and is doing well means that working with this messed-up specimen is useless. Shouldn\u0027t it be scrapped?\"\n \"In short, Alfred, you are annoyed that I am wasting my so-valuable time. Feel relieved. My time is not being wasted. I am working with this robot.\"\n \"But the work has no meaning.\"\n \"I\u0027ll be the judge of that, Alfred.\" Her voice was ominously quiet, and Lanning thought it wiser to shift his ground.\n \"Will you tell me what meaning it has? What are you doing with it right now, for instance?\"\n \"I\u0027m trying to get it to raise its hand on the word of command. I\u0027m trying to get it to imitate the sound of the word.\"\n As though on cue, Lenny said, \"Eh-uh\"And raised its hand waveringly.\n Lanning shook his head. \"That voice is amazing. How does it happen?\"\n Susan Calvin said, \"I don\u0027t quite know. Its transmitter is a normal one. It could speak normally, I\u0027m sure. It doesn\u0027t, however; it speaks like this as a consequence of something in the positronic paths that I have not yet pinpointed.\"\n \"Well, pinpoint it, for Heaven\u0027s sake. Speech like that might be useful.\"\n \"Oh, then there is some possible use in my studies on Lenny?\" Lanning shrugged in embarrassment. \"Oh, well, it\u0027s a minor point.\"\n \"I\u0027m sorry you don\u0027t see the major points, then,\" said Susan Calvin with asperity, \"which are much more important, but that\u0027s not my fault. Would you leave now, Alfred, and let me go on with my work?\"\n Lanning got to his cigar, eventually, in Bogert\u0027s office. He said, sourly, \"That woman is growing more peculiar daily.\"\n Bogert understood perfectly. In the U. S. Robots and Mechanical Men Corporation, there was only one \"that woman.\" He said, \"Is she still scuffing about with that pseudo-robot-that Lenny of hers?\"\n \"Trying to get it to talk, so help me.\" Bogert shrugged. \"Points up the company problem. I mean, about getting qualified personnel for research. If we had other robopsychologists, we could retire Susan. Incidentally, I presume the directors\u0027 meeting scheduled for tomorrow is for the purpose of dealing with the procurement problem?\"\n Lanning nodded and looked at his cigar as though it didn\u0027t taste good. \"Yes. Quality, though, not quantity. We\u0027ve raised wages until there\u0027s a steady stream of applicants-those who are interested primarily in money. The trick is to get those who are interested primarily in robotics-a few more like Susan Calvin.\"\n \"Hell, no. Not like her.\"\n \"Well, not like her personally. But you\u0027ll have to admit, Peter, that she\u0027s single-minded about robots. She has no other interest in life.\"\n \"I know. And that\u0027s exactly what makes her so unbearable.\" Lanning nodded. He had lost count of the many times it would have done his soul good to have fired Susan Calvin. He had also lost count of the number of millions of dollars she had at one time or another saved the company. She was a truly indispensable woman and would remain one until she died-or until they could lick the problem of finding men and women of her own high caliber who were interested in robotics research.\n He said, \"I think we\u0027ll cut down on the tour business.\" Peter shrugged. \"If you say so. But meanwhile, seriously, what do we do about Susan? She can easily tie herself up with Lenny indefinitely. You know how she is when she gets what she considers an interesting problem.\"\n \"What can we do?\" said Lanning. \"If we become too anxious to pull her off, she\u0027ll stay on out of feminine contrariness. In the last analysis, we can\u0027t force her to do anything.\"\n The dark-haired mathematician smiled. \"I wouldn\u0027t ever apply the adjective \u0027feminine\u0027 to any part of her.\"\n \"Oh, well,\" said Lanning, grumpily. \"At least, it won\u0027t do anyone any actual harm.\"\n In that, if in nothing else, he was wrong. The emergency signal is always a tension-making thing in any large industrial establishment. Such signals had sounded in the history of U. S. Robots a dozen times-for fire, flood, riot and insurrection.\n But one thing had never occurred in all that time. Never had the particular signal indicating \"Robot out of control\" sounded. No one ever expected it to sound. It was only installed at government insistence. (\"Damn the Frankenstein complex,\" Lanning would mutter on those rare occasions when he thought of it.)\n Now, finally, the shrill siren rose and fell at ten-second intervals, and practically no worker from the President of the Board of Directors down to the newest janitor\u0027s assistant recognized the significance of the strange sound for a few moments. After those moments passed, there was a massive convergence of armed guards and medical men to the indicated area of danger and U. S. Robots was struck with paralysis.\n Charles Randow, computing technician, was taken off to hospital level with a broken arm. There was no other damage. No other physical damage.\n \"But the moral damage,\" roared Lanning, \"is beyond estimation.\"\n Susan Calvin faced him, murderously calm. \"You will do nothing to Lenny. Nothing. Do you understand?\"\n \"Do you understand, Susan?\" That thing has hurt a human being. It has broken First Law. Don\u0027t you know what First Law is?\"\n \"You will do nothing to Lenny.\"\n \"For God\u0027s sake, Susan, do I have to tell you First Law? A robot may not harm a human being or, through inaction, allow a human being to come to harm. Our entire position depends on the fact that First Law is rigidly observed by all robots of all types. If the public should hear, and they will hear, that there was an exception, even one exception, we might be forced to close down altogether. Our only chance of survival would be to announce at once that the robot involved had been destroyed, explain the circumstances, and hope that the public can be convinced that it will never happen again.\"\n \"I would like to find out exactly what happened,\" said Susan Calvin. \"I was not present at the time and I would like to know exactly what the Randow boy was doing in my laboratories without my permission.\"\n \"The important thing that happened,\" said Lanning, \"is obvious. Your robot struck Randow and the damn fool flashed the \u0027Robot out of control\u0027 button and made a case of it. But your robot struck him and inflicted damage to the extent of a broken arm. The truth is your Lenny is so distorted it lacks First Law and it must be destroyed.\"\n \"It does not lack First Law. I have studied its brainpaths and know it does not lack it.\"\n \"Then how could it strike a man?\" Desperation turned him to sarcasm. \"Ask Lenny. Surely you have taught it to speak by now.\"\n Susan Calvin\u0027s cheeks Bushed a painful pink. She said, \"I prefer to interview the victim. And in my absence, Alfred, I want my offices sealed tight, with Lenny inside. I want no one to approach him. If any harm comes to him while I am gone, this company will not see me again under any circumstances.\"\n \"Will you agree to its destruction, if it has broken First Law?\"\n \"Yes,\" said Susan Calvin, \"because I know it hasn\u0027t.\"\n Charles Randow lay in bed with his arm set and in a cast. His major suffering was still from the shock of those few moments in which he thought a robot was advancing on him with murder in its positronic mind. No other human had ever had such reason to fear direct robotic harm as he had had just then. He had had a unique experience.\n Susan Calvin and Alfred Lanning stood beside his bed now; Peter Bogert, who had met them on the way, was with them. Doctors and nurses had been shooed out.\n Susan Calvin said, \"Now-what happened?\" Randow was daunted. He muttered, \"The thing hit me in the arm. It was coming at me.\"\n Calvin said, \"Move further back in the story. What were you doing in my laboratory without authorization?\"\n The young computer swallowed, and the Adam\u0027s apple in his thin neck bobbed noticeably. He was high-cheekboned and abnormally pale. He said, \"We all knew about your robot. The word is you were trying to teach it to talk like a musical instrument. There were bets going as to whether it talked or not. Some said-uh-you could teach a gatepost to talk.\"\n \"I suppose,\" said Susan Calvin, freezingly, \"that is meant as a compliment. What did that have to do with you?\"\n \"I was supposed to go in there and settle matters-see if it would talk, you know. We swiped a key to your place and I waited till you were gone and went in. We had a lottery on who was to do it. I lost.\"\n \"Then?\"\n \"I tried to get it to talk and it hit me.\"\n \"What do you mean, you tried to get it to talk? How did you try?\"\n \"I-I asked it questions, but it wouldn\u0027t say anything, and I had to give the thing a fair shake, so I kind of-yelled at it, and-\"\n \"And?\"\n There was a long pause. Under Susan Calvin\u0027s unwavering stare, Randow finally said, \"I tried to scare it into saying something.\" He added defensively, \"I had to give the thing a fair shake.\"\n \"How did you try to scare it?\"\n \"I pretended to take a punch at it.\"\n \"And it brushed your arm aside?\"\n \"It hit my arm.\"\n \"Very well. That\u0027s all.\" To Lanning and Bogert, she said, \"Come, gentlemen.\"\n At the doorway, she turned back to Randow. \"I can settle the bets going around, if you are still interested. Lenny can speak a few words quite well.\"\n They said nothing until they were in Susan Calvin\u0027s office. Its walls were lined with her books, some of which she had written herself. It retained the patina of her own frigid, carefully ordered personality. It had only one chair in it and she sat down. Lanning and Bogert remained standing.\n She said, \"Lenny only defended itself. That is the Third Law: A robot must protect its own existence.\"\n \"Except,\" said Lanning forcefully, \"when this conflicts with the First or Second Laws. Complete the statement! Lenny had no right to defend itself in any way at the cost of harm, however minor, to a human being.\"\n \"Nor did it,\" shot back Calvin, \"knowingly. Lenny has an aborted brain. It had no way of knowing its own strength or the weakness of humans. In brushing aside the threatening arm of a human being it could not know the bone would break. In human terms, no moral blame can be attached to an individual who honestly cannot differentiate good and evil.\"\n Bogert interrupted, soothingly, \"Now, Susan, we don\u0027t blame. We understand that Lenny is the equivalent of a baby, humanly speaking, and we don\u0027t blame it. But the public will. U. S. Robots will be closed down.\"\n \"Quite the opposite. If you had the brains of a flea, Peter, you would see that this is the opportunity U. S. Robots is waiting for. That this will solve its problems.\"\n Lanning hunched his white eyebrows low. He said, softly, \"What problems, Susan?\"\n \"Isn\u0027t the corporation concerned about maintaining our research personnel at the present-Heaven help us-high level?\"\n \"We certainly are.\"\n \"Well, what are you offering prospective researchers? Excitement? Novelty? The thrill of piercing the unknown? No! You offer them salaries and the assurance of no problems.\"\n Bogert said, \"How do you mean, no problems?\"\n \"Are there problems?\" shot back Susan Calvin. \"What kind of robots do we turn out? Fully developed robots, fit for their tasks. An industry tells us what it needs; a computer designs the brain; machinery forms the robot; and there it is, complete and done. Peter, some time ago, you asked me with reference to Lenny what its use was. What\u0027s the use, you said, of a robot that was not designed for any job? Now I ask you-what\u0027s the use of a robot designed for only one job? It begins and ends in the same place. The LNE models mine boron. If beryllium is needed, they are useless. If boron technology enters a new phase, they become useless. A human being so designed would be sub-human. A robot so designed is sub-robotic.\"\n \"Do you want a versatile robot?\" asked Lanning, incredulously. \"Why not?\" demanded the robopsychologist. \"Why not? I\u0027ve been handed a robot with a brain almost completely stultified. I\u0027ve been teaching it, and you, Alfred, asked me what was the use of that. Perhaps very little as far as Lenny itself is concerned, since it will never progress beyond the five-year-old level on a human scale. But what\u0027s the use in general? A very great deal, if you consider it as a study in the abstract problem of learning how to teach robots. I have learned ways to short-circuit neighboring pathways in order to create new ones. More study will yield better, more subtle and more efficient techniques of doing so.\"\n \"Well?\"\n \"Suppose you started with a positronic brain that had all the basic pathways carefully outlined but none of the secondaries. Suppose you then started creating secondaries. You could sell basic robots designed for instruction; robots that could be modeled to a job, and then modeled to another, if necessary. Robots would become as versatile as human beings. Robots could learn!\"\n They stared at her. She said, impatiently, \"You still don\u0027t understand, do you?\"\n \"I understand what you are saying,\" said Lanning.\n \"Don\u0027t you understand that with a completely new field of research and completely new techniques to be developed, with a completely new area of the unknown to be penetrated, youngsters will feel a new urge to enter robotics? Try it and see.\"\n \"May I point out,\" said Bogert, smoothly, \"that this is dangerous. Beginning with ignorant robots such as Lenny will mean that one could never trust First Law-exactly as turned out in Lenny\u0027s case.\"\n \"Exactly. Advertise the fact.\"\n \"Advertise it!\"\n \"Of course. Broadcast the danger. Explain that you will set up a new research institute on the moon, if Earth\u0027s population chooses not to allow this sort of thing to go on upon Earth, but stress the danger to the possible applicants by all means.\"\n Lanning said, \"For God\u0027s sake, why?\"\n \"Because the spice of danger will add to the lure. Do you think nuclear technology involves no danger and spationautics no peril? Has your lure of absolute security been doing the trick for you? Has it helped you to cater to the Frankenstein complex you all despise so? Try something else then, something that has worked in other fields.\"\n There was a sound from beyond the door that led to Calvin\u0027s personal laboratories. It was the chiming sound of Lenny.\n The robopsychologist broke off instantly, listening. She said, \"Excuse me. I think Lenny is calling me.\"\n \"Can it call you?\" said Lanning.\n \"I said I\u0027ve managed to teach it a few words.\" She stepped toward the door, a little flustered. \"If you will wait for me-\"\n They watched her leave and were silent for a moment. Then Lanning said, \"Do you think there\u0027s anything to what she says, Peter?\"\n \"Just possibly, Alfred,\" said Bogert. \"Just possibly. Enough for US to bring the matter up at the directors\u0027 meeting and see what they say. After all, the fat is in the fire. A robot has harmed a human being and knowledge of it is public. As Susan says, we might as well try to turn the matter to our advantage. Of course, I distrust her motives in all this.\"\n \"How do you mean?\"\n \"Even if all she has said is perfectly true, it is only rationalization as far as she is concerned. Her motive in all this is her desire to hold on to this robot. If we pressed her\" (and the mathematician smiled at the incongruous literal meaning of the phrase) \"she would say it was to continue learning techniques of teaching robots, but I think she has found another use for Lenny. A rather unique one that would fit only Susan of all women.\"\n \"I don\u0027t get your drift.\" Bogert said, \"Did you hear what the robot was calling?\"\n \"Well, no, I didn\u0027t quite-\" began Lanning, when the door opened suddenly, and both men stopped talking at once.\n Susan Calvin stepped in again, looking about uncertainly. \"Have either of you seen-I\u0027m positive I had it somewhere about-Oh, there it is.\"\n She ran to a corner of one bookcase and picked up an object of intricate metal webbery, dumbbell shaped and hollow, with variously shaped metal pieces inside each hollow, just too large to be able to fallout of the webbing.\n As she picked it up, the metal pieces within moved and struck together, clicking pleasantly. It struck Lanning that the object was a kind of robotic version of a baby rattle.\n As Susan Calvin opened the door again to pass through, Lenny\u0027s voice chimed again from within. This time, Lanning heard it clearly as it spoke the words Susan Calvin had taught it.\n In heavenly celeste-like sounds, it called out, \"Mommie, I want you. I want you, Mommie.\"\n And the footsteps of Susan Calvin could be heard hurrying eagerly across the laboratory floor toward the only kind of baby she could ever have or love. \n","sourceLink":"https://allnovel.net/robot-visions-robot-0-5/page-17.html","bookId":1742,"book":{"id":1742,"title":"Robot Visions (Robot #0.5)","description":"Storyline: \n Robot Visions (Robot 0.5) \n From Isaac Asimov, the writer whose name is synonymous with robots and the science of robotics, here are five decades of robot visions--thirty-four landmark stories and essays, including three rare tales--gathered together in one volume. \n Meet all of Asimov\u0027s most famous creations: Robbie, the very first robot that his imagination brought to life; Susan Calvin, the original robot psychologist; Stephen Byerley, the humanoid robot; and the famous human-robot detective team of Lije Baley and R. Daneel Olivaw, who have appeared in such bestselling novesl as The Robots of Dawn and Robots and Empire. \n Let the master himself guide you through the key moments in the fictional history of robot-human relations--from the most primitive computers and movile machines to the first robot to become a man. (Description from back cover)\n \n","cover":"https://allnovel.net/images/robot-visions-robot-0-5.jpg","author":"Isaac Asimov","type":"Science Fiction","source":"allnovel","link":"https://allnovel.net/robot-visions-robot-0-5.html","creation":"Oct 5, 2019 8:57:55 AM","modification":"Oct 5, 2019 10:15:59 AM"}}
